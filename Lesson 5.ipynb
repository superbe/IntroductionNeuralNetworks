{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курс «Введение в нейронные сети»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Урок 5. Рекуррентные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашняя работа к уроку 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте изменить параметры нейронной сети работающей с датасетом imdb так, чтобы улучшить ее точность. Приложите анализ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала вопроизводим то, что на уроке, потом уже меняем парметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем начальные значения параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выравниваем длину подпоследовательностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Построение модели...\n"
     ]
    }
   ],
   "source": [
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Компилируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения...\n",
      "500/500 [==============================] - 61s 120ms/step - loss: 0.5208 - accuracy: 0.7188 - val_loss: 0.3591 - val_accuracy: 0.8420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e08c39e7c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3591 - accuracy: 0.8420\n",
      "Результат при тестировании: 0.3590894043445587\n",
      "Тестовая точность: 0.8419600129127502\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем можно поиграться:\n",
    "<ol>\n",
    "    <li>max_features</li>\n",
    "    <li>maxlen</li>\n",
    "    <li>batch_size</li>\n",
    "    <li>optimizer</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим количество эпох до 15, будем считать что до этого значения точность будет расти быстро, а после будет расти медленнее (по итогам прошлых домашних заданий)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**num_words** - величина ранжирования слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно малое значение num_words нам ничего не даст. Найдем слово с максимальным рангом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88586\n"
     ]
    }
   ],
   "source": [
    "max_value = 0\n",
    "for i in range(len(x_train)):\n",
    "    if (max(x_train[i]) > max_value):\n",
    "        max_value = max(x_train[i])\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88584\n"
     ]
    }
   ],
   "source": [
    "max_value = 0\n",
    "for i in range(len(x_test)):\n",
    "    if (max(x_test[i]) > max_value):\n",
    "        max_value = max(x_test[i])\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Если мы будем усекать этот параметр, то может так случиться, что наша сеть будет получать одни и теже значения и обучения не произойдет, поэтому оставим этот параметр по умолчанию, т.е. будуем вызыват его со значением по умолчанию, т.е. None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**maxlen** - величина усечения, максимальная длина всех последовательностей. Если не указан, последовательности будут дополнены до длины самой длинной отдельной последовательности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 2494)\n",
      "x_test shape: (25000, 2315)\n"
     ]
    }
   ],
   "source": [
    "x_train_1 = sequence.pad_sequences(x_train)\n",
    "x_test_1 = sequence.pad_sequences(x_test)\n",
    "print('x_train shape:', x_train_1.shape)\n",
    "print('x_test shape:', x_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "min_value = 25000\n",
    "for i in range(len(x_train)):\n",
    "    if (len(x_train[i]) < min_value):\n",
    "        min_value = len(x_train[i])\n",
    "print(min_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Диапазон подпоследовательностей от 11 до 2494."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим следующие значения диапазона: 10, 60, 110, 160, 210. Больше брать не будем, чтобы нейросетка долго не считалась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen: 210\n",
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 210)\n",
      "x_test shape: (25000, 210)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 205s 407ms/step - loss: 0.5445 - accuracy: 0.6993 - val_loss: 0.3184 - val_accuracy: 0.8699\n",
      "500/500 [==============================] - 19s 37ms/step - loss: 0.3184 - accuracy: 0.8699\n",
      "Результат при тестировании: 0.31836071610450745\n",
      "Тестовая точность: 0.869920015335083 \n",
      "\n",
      "maxlen: 160\n",
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 160)\n",
      "x_test shape: (25000, 160)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 154s 305ms/step - loss: 0.5038 - accuracy: 0.7346 - val_loss: 0.3287 - val_accuracy: 0.8582\n",
      "500/500 [==============================] - 16s 33ms/step - loss: 0.3287 - accuracy: 0.8582\n",
      "Результат при тестировании: 0.32870545983314514\n",
      "Тестовая точность: 0.8581600189208984 \n",
      "\n",
      "maxlen: 110\n",
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 110)\n",
      "x_test shape: (25000, 110)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 96s 190ms/step - loss: 0.5620 - accuracy: 0.6880 - val_loss: 0.3493 - val_accuracy: 0.8486\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.3493 - accuracy: 0.8486\n",
      "Результат при тестировании: 0.3493329584598541\n",
      "Тестовая точность: 0.8485999703407288 \n",
      "\n",
      "maxlen: 60\n",
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 60)\n",
      "x_test shape: (25000, 60)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 57s 113ms/step - loss: 0.5218 - accuracy: 0.7155 - val_loss: 0.3983 - val_accuracy: 0.8212\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.3983 - accuracy: 0.8212\n",
      "Результат при тестировании: 0.3983440101146698\n",
      "Тестовая точность: 0.8211600184440613 \n",
      "\n",
      "maxlen: 10\n",
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 10)\n",
      "x_test shape: (25000, 10)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 25s 47ms/step - loss: 0.6097 - accuracy: 0.6464 - val_loss: 0.5266 - val_accuracy: 0.7257\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.5266 - accuracy: 0.7257\n",
      "Результат при тестировании: 0.5266367793083191\n",
      "Тестовая точность: 0.7257199883460999 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 50\n",
    "\n",
    "for i in range(210, 9, -50):\n",
    "    print('maxlen:', i)\n",
    "    print('Загрузка данных...')\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    print(len(x_train), 'тренировочные последовательности')\n",
    "    print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "    print('Pad последовательности (примеров в x единицу времени)')\n",
    "    x_train = sequence.pad_sequences(x_train, maxlen=i)\n",
    "    x_test = sequence.pad_sequences(x_test, maxlen=i)\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "\n",
    "    print('Построение модели...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    print('Процесс обучения...')\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "    score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "    print('Результат при тестировании:', score)\n",
    "    print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** при короткой отсечке точность падает, при отсечке порядка 100 слов на сообщение точность существенно уже не меняется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем оптимизатор:\n",
    "<ol>\n",
    "    <li>SGD — оптимизатор градиентного спуска (с импульсом).</li>\n",
    "    <li>RMSprop — оптимизатор, реализующий алгоритм RMSprop: поддержание скользящего среднего квадрата градиентов и разделение градиента на корень этого среднего.</li>\n",
    "    <li>Adam — оптимизатор, реализующий метод стохастического градиентного спуска, основанный на адаптивной оценке моментов первого и второго порядка.</li>\n",
    "    <li>Adadelta — оптимизатор, реализующий метод стохастического градиентного спуска, основанный на скорости адаптивного обучения по каждому измерению и устраняющий два недостатка: постоянное снижение темпов обучения на протяжении всего обучения; необходимость в выбранной вручную глобальной скорости обучения</li>\n",
    "    <li>Adagrad — оптимизатор со скоростью обучения, зависящей от параметра, которая адаптирована в зависимости от того, как часто параметр обновляется во время обучения, чем больше обновлений получает параметр, тем меньше обновлений.</li>\n",
    "    <li>Adamax — вариант Adam, основанный на норме бесконечности. Параметры по умолчанию соответствуют указанным в документе. Иногда Adamax превосходит Adam, особенно в моделях с вложениями.</li>\n",
    "    <li>Nadam — это Adam с импульсом Нестерова.</li>\n",
    "    <li>Ftrl — оптимизатор, реализующий алгоритм FTRL.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 89s 176ms/step - loss: 0.6930 - accuracy: 0.5150 - val_loss: 0.6929 - val_accuracy: 0.5174\n",
      "500/500 [==============================] - 12s 25ms/step - loss: 0.6929 - accuracy: 0.5174\n",
      "Результат при тестировании: 0.6928873658180237\n",
      "Тестовая точность: 0.5174000263214111 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSprop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 91s 179ms/step - loss: 0.5258 - accuracy: 0.7333 - val_loss: 0.3392 - val_accuracy: 0.8541\n",
      "500/500 [==============================] - 11s 23ms/step - loss: 0.3392 - accuracy: 0.8541\n",
      "Результат при тестировании: 0.33921995759010315\n",
      "Тестовая точность: 0.8540800213813782 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 98s 194ms/step - loss: 0.5109 - accuracy: 0.7285 - val_loss: 0.3493 - val_accuracy: 0.8487\n",
      "500/500 [==============================] - 10s 21ms/step - loss: 0.3493 - accuracy: 0.8487\n",
      "Результат при тестировании: 0.3493058979511261\n",
      "Тестовая точность: 0.8486800193786621 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adadelta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 81s 160ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.4974\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "Результат при тестировании: 0.6931918263435364\n",
      "Тестовая точность: 0.49744001030921936 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adagrad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 81s 160ms/step - loss: 0.6932 - accuracy: 0.5046 - val_loss: 0.6932 - val_accuracy: 0.4969\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.6932 - accuracy: 0.4969\n",
      "Результат при тестировании: 0.6931880712509155\n",
      "Тестовая точность: 0.49691998958587646 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='Adagrad', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adamax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 81s 161ms/step - loss: 0.5713 - accuracy: 0.6780 - val_loss: 0.3684 - val_accuracy: 0.8381\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.3684 - accuracy: 0.8381\n",
      "Результат при тестировании: 0.3684289753437042\n",
      "Тестовая точность: 0.8380799889564514 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nadam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 92s 182ms/step - loss: 0.5237 - accuracy: 0.7230 - val_loss: 0.3506 - val_accuracy: 0.8488\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.3506 - accuracy: 0.84880s - l\n",
      "Результат при тестировании: 0.35064640641212463\n",
      "Тестовая точность: 0.8487600088119507 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ftrl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 79s 157ms/step - loss: 0.6931 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Результат при тестировании: 0.6931463479995728\n",
      "Тестовая точность: 0.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='Ftrl', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** самый худший результат показал оптимизатор Ftrl, самую лучшую точность показал оптимизатор RMSprop (он самый долгий, но самый точный). Неплохую точность показали оптимизаторы семейства Adam на уровне оптимизатора RMSprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем поменять слои."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 слой LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 94s 185ms/step - loss: 0.5193 - accuracy: 0.7441 - val_loss: 0.3703 - val_accuracy: 0.8470\n",
      "500/500 [==============================] - 11s 22ms/step - loss: 0.3703 - accuracy: 0.8470\n",
      "Результат при тестировании: 0.3703368604183197\n",
      "Тестовая точность: 0.8469600081443787 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 слоя LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 95s 188ms/step - loss: 102227507.4488 - accuracy: 0.6294 - val_loss: 1.9524 - val_accuracy: 0.7432\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 1.9524 - accuracy: 0.7432\n",
      "Результат при тестировании: 1.9524117708206177\n",
      "Тестовая точность: 0.7431600093841553 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 слоя LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 148s 293ms/step - loss: nan - accuracy: 0.5035 - val_loss: nan - val_accuracy: 0.5000\n",
      "500/500 [==============================] - 30s 59ms/step - loss: nan - accuracy: 0.5000\n",
      "Результат при тестировании: nan\n",
      "Тестовая точность: 0.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 слоя LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "500/500 [==============================] - 241s 479ms/step - loss: 41490029490217.2109 - accuracy: 0.5653 - val_loss: 8.9476 - val_accuracy: 0.6985\n",
      "500/500 [==============================] - 42s 83ms/step - loss: 8.9476 - accuracy: 0.6985\n",
      "Результат при тестировании: 8.947563171386719\n",
      "Тестовая точность: 0.6984800100326538 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** чем больше слоев LSTM, тем больше падает точность, самое оптимальное, это 1 слой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итоговая настроенная модель:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "Epoch 1/15\n",
      "250/250 [==============================] - 87s 345ms/step - loss: 0.5554 - accuracy: 0.7252 - val_loss: 0.3531 - val_accuracy: 0.8474\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 86s 346ms/step - loss: 0.2878 - accuracy: 0.8857 - val_loss: 0.3610 - val_accuracy: 0.8532\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 87s 347ms/step - loss: 0.2342 - accuracy: 0.9095 - val_loss: 0.3463 - val_accuracy: 0.8469\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 87s 346ms/step - loss: 0.1928 - accuracy: 0.9270 - val_loss: 0.4199 - val_accuracy: 0.8499\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 86s 345ms/step - loss: 0.1612 - accuracy: 0.9400 - val_loss: 0.3573 - val_accuracy: 0.8488\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - 87s 346ms/step - loss: 0.1347 - accuracy: 0.9520 - val_loss: 0.3793 - val_accuracy: 0.8428\n",
      "Epoch 7/15\n",
      "250/250 [==============================] - 86s 343ms/step - loss: 0.1130 - accuracy: 0.9597 - val_loss: 0.4796 - val_accuracy: 0.8363\n",
      "Epoch 8/15\n",
      "250/250 [==============================] - 87s 346ms/step - loss: 0.0935 - accuracy: 0.9671 - val_loss: 0.4554 - val_accuracy: 0.8372\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - 86s 346ms/step - loss: 0.0875 - accuracy: 0.9697 - val_loss: 0.4750 - val_accuracy: 0.8347\n",
      "Epoch 10/15\n",
      "250/250 [==============================] - 86s 345ms/step - loss: 0.0666 - accuracy: 0.9773 - val_loss: 0.5841 - val_accuracy: 0.8270\n",
      "Epoch 11/15\n",
      "250/250 [==============================] - 86s 346ms/step - loss: 0.0559 - accuracy: 0.9806 - val_loss: 0.5099 - val_accuracy: 0.8314\n",
      "Epoch 12/15\n",
      "250/250 [==============================] - 86s 342ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.5664 - val_accuracy: 0.8279\n",
      "Epoch 13/15\n",
      "250/250 [==============================] - 87s 346ms/step - loss: 0.0347 - accuracy: 0.9889 - val_loss: 0.7112 - val_accuracy: 0.8265\n",
      "Epoch 14/15\n",
      "250/250 [==============================] - 87s 348ms/step - loss: 0.0313 - accuracy: 0.9893 - val_loss: 0.6804 - val_accuracy: 0.8236\n",
      "Epoch 15/15\n",
      "250/250 [==============================] - 87s 348ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.9315 - val_accuracy: 0.8011\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 0.9315 - accuracy: 0.8011\n",
      "Результат при тестировании: 0.9314731359481812\n",
      "Тестовая точность: 0.8010799884796143 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 100\n",
    "batch_size = 100\n",
    "\n",
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=15, validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы:**\n",
    "<ol>\n",
    "    <li>max_features сделать максимальным не получится, так как сверх 20000 возникает ошибка, оставляем так.</li>\n",
    "    <li>Самый оптимальный размер усечения 80-100 слов на сообщение.</li>\n",
    "    <li>Самый оптимальный оптимизатор RMSprop, от него не отстает семейство оптимизаторов Adam, остальные так себе.</li>\n",
    "    <li>Слоев LSTM оптимально 1-2, что сверх ведет к потере точности.</li>\n",
    "    <li>Чем больше batch_size, тем быстрее считается, но при этом точность несколько падает.</li>\n",
    "    <li>Оптимальное значение эпох обучения 14-15, после чего точность существенно не растет и даже может падать.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте изменить параметры нейронной сети генерирующий текст таким образом, чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший получившейся у вас текст и опишите, что вы предприняли, чтобы его получить. Можно использовать текст другого прозведения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем сразу работать с оптимальными параметрами. В качестве обучающей выборки возьмем все романы Ф. М. Достоевского."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построчное чтение текстов\n",
    "for i in range(1, 12, 1):\n",
    "    lines = []\n",
    "    with open(f'dostoevsky/00{i}.txt' if i < 10 else f'dostoevsky/0{i}.txt', 'rb') as _in:\n",
    "        for line in _in:\n",
    "            line = line.strip().lower().decode()\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            lines.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собрали текст в единый массив."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(lines)\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
    "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
    "# число при использовании one-hot кодировки для представление входов символов\n",
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQLEN, STEP = 50, 1\n",
    "input_chars, label_chars = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 128, 128\n",
    "NUM_ITERATIONS = 2\n",
    "NUM_EPOCHS_PER_ITERATION = 10\n",
    "NUM_PREDS_PER_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 0\n",
      "Epoch 1/10\n",
      "4865/4865 [==============================] - 286s 58ms/step - loss: 2.5292\n",
      "Epoch 2/10\n",
      "4865/4865 [==============================] - 280s 58ms/step - loss: 1.9518\n",
      "Epoch 3/10\n",
      "4865/4865 [==============================] - 280s 58ms/step - loss: 1.7995\n",
      "Epoch 4/10\n",
      "4865/4865 [==============================] - 280s 58ms/step - loss: 1.7162\n",
      "Epoch 5/10\n",
      "4865/4865 [==============================] - 281s 58ms/step - loss: 1.6658\n",
      "Epoch 6/10\n",
      "4865/4865 [==============================] - 282s 58ms/step - loss: 1.6277\n",
      "Epoch 7/10\n",
      "4865/4865 [==============================] - 282s 58ms/step - loss: 1.6016\n",
      "Epoch 8/10\n",
      "4865/4865 [==============================] - 281s 58ms/step - loss: 1.5789\n",
      "Epoch 9/10\n",
      "4865/4865 [==============================] - 282s 58ms/step - loss: 1.5636\n",
      "Epoch 10/10\n",
      "4865/4865 [==============================] - 282s 58ms/step - loss: 1.5498\n",
      "Генерация из посева: авненно ничтожнее, чем того, главного убийцу, жела\n",
      "авненно ничтожнее, чем того, главного убийцу, желали в том же в постельки подозрения совсем не подумал он в том же в постельки подозрения совсем не по==================================================\n",
      "Итерация #: 1\n",
      "Epoch 1/10\n",
      "4865/4865 [==============================] - 274s 56ms/step - loss: 1.5414\n",
      "Epoch 2/10\n",
      "4865/4865 [==============================] - 277s 57ms/step - loss: 1.5317\n",
      "Epoch 3/10\n",
      "4865/4865 [==============================] - 277s 57ms/step - loss: 1.5232\n",
      "Epoch 4/10\n",
      "4865/4865 [==============================] - 277s 57ms/step - loss: 1.5154\n",
      "Epoch 5/10\n",
      "4865/4865 [==============================] - 277s 57ms/step - loss: 1.5089\n",
      "Epoch 6/10\n",
      "4865/4865 [==============================] - 277s 57ms/step - loss: 1.5029\n",
      "Epoch 7/10\n",
      "4865/4865 [==============================] - 277s 57ms/step - loss: 1.4978\n",
      "Epoch 8/10\n",
      "4865/4865 [==============================] - 277s 57ms/step - loss: 1.4931\n",
      "Epoch 9/10\n",
      "4865/4865 [==============================] - 277s 57ms/step - loss: 1.4887\n",
      "Epoch 10/10\n",
      "4865/4865 [==============================] - 277s 57ms/step - loss: 1.4845\n",
      "Генерация из посева:  титулярного советника Федора Павловича Карамазова\n",
      " титулярного советника Федора Павловича Карамазова в сердце своей страдание совсем не понимают пристально просто тогда пришел в самом деле в тот же се\n"
     ]
    }
   ],
   "source": [
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** На качество очень сильно влияют объем исходного текста, длина отсеченной фразы, количество итераций и количество эпох. Хотел сделать разбиение на фразы с учетом правильной разбивки на слова без лишних обрывков слов, но не получилось, не хватило мощности компьютера. Самая удачная фраза: \"титулярного советника Федора Павловича Карамазова в сердце своей страдание совсем не понимают пристально просто тогда пришел в самом деле в тот же\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
